import yaml
import json
import pandas as pd
import numpy as np
import torch
from data_loader import get_dataloaders, extract_names_from_text_json, set_seed
from model import InteractionPredictionModel_NoAttention, InteractionPredictionModel


def predict(model, dataloader):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()

    scores = []
    with torch.no_grad():
        for inputs, _ in dataloader:
            (cd, cp, cs, pd, pp, ps) = inputs
            cd, cp, cs, pd, pp, ps = cd.to(device), cp.to(device), cs.to(device), pd.to(device), pp.to(device), ps.to(device)
            logits = model(cd, cp, cs, pd, pp, ps)
            probs = torch.sigmoid(logits).cpu().numpy().ravel()
            scores.extend(probs.tolist())
    return np.array(scores)


def save_topk_per_compound(scores, protein_names, compound_names, output_path, topk=20):
    """
    ä½¿ç”¨pandasçš„ç®€æ´ç‰ˆæœ¬
    """
    # åˆ›å»ºDataFrame
    df = pd.DataFrame({
        'Compound': compound_names,
        'Protein': protein_names,
        'Score': scores
    })

    # æŒ‰åŒ–åˆç‰©åˆ†ç»„ï¼Œå¯¹æ¯ä¸ªåŒ–åˆç‰©æŒ‰åˆ†æ•°æ’åº
    results = {}

    # ä½¿ç”¨groupbyå¤„ç†
    for compound, group in df.groupby('Compound'):
        # æ’åºå¹¶å–TopK
        sorted_group = group.sort_values('Score', ascending=False).head(topk)

        results[compound] = {
            "Protein Names": sorted_group['Protein'].tolist(),
            "Prediction Scores": sorted_group['Score'].tolist(),
            "Score Type": "sigmoid_probability"
        }

    # ä¿å­˜
    with open(output_path, 'w') as f:
        json.dump(results, f, indent=4)

    print(f"å·²ä¿å­˜ {len(results)} ä¸ªåŒ–åˆç‰©çš„Top{topk}ç»“æœåˆ°: {output_path}")
    return results


def DeepETD_predict(config_path='predict_config.yaml'):
    """

    :param config_path:
    :return:
    """
    # åŠ è½½é…ç½®
    with open(config_path, 'r') as f:
        cfg = yaml.safe_load(f)

    # è®¾ç½®éšæœºç§å­
    set_seed(cfg['prediction']['seed'])

    # è·å–æ•°æ®åŠ è½½å™¨
    loaded = get_dataloaders(
        disease_json_path=cfg['data']['disease_json'],
        phenotype_json_path=cfg['data']['phenotype_json'],
        positive_json_path=cfg['data']['positive_json'],
        negative_json_path=cfg['data']['negative_json'],
        text_json_path=cfg['data']['text_json'],
        batch_size=cfg['prediction']['batch_size'],
        val_split=cfg['prediction']['val_split'],
        seed=cfg['prediction']['seed'],
    )

    enc = loaded['encoders']
    model_params = cfg['model']['params'].copy()
    model_params.update({
        'num_diseases': len(enc['disease'].classes_),
        'num_phenotypes': len(enc['phenotype'].classes_),
        'num_subcellular_locations': len(enc['subcellular'].classes_),
    })

    model_class = InteractionPredictionModel if cfg['model']['use_attention'] \
        else InteractionPredictionModel_NoAttention
    model = model_class(**model_params)

    state = torch.load(cfg['model']['checkpoint'], map_location='cpu')
    model.load_state_dict(state)

    layer_stats = diagnose_model_issues(model, loaded['text'], loaded['encoders'])

    protein_names, compound_names = extract_names_from_text_json(cfg['data']['text_json'])

    scores = predict(model, loaded['text'])

    n = min(len(scores), len(protein_names), len(compound_names))
    save_topk_per_compound(
        scores[:n],
        protein_names[:n],
        compound_names[:n],
        cfg['prediction']['output_file'],
        topk=cfg['prediction']['topk']
    )


def diagnose_model_issues(model, dataloader, encoders):
    """
    è¯Šæ–­æ¨¡å‹é—®é¢˜çš„æ ¹æœ¬åŸå› 
    """
    print("ğŸ” å¼€å§‹æ¨¡å‹è¯Šæ–­...")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    # 1. æ£€æŸ¥æ¨¡å‹å‚æ•°
    print("\n1. æ¨¡å‹å‚æ•°æ£€æŸ¥:")
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"   æ€»å‚æ•°: {total_params:,}")
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"   å†»ç»“å‚æ•°: {total_params - trainable_params:,}")

    # æ£€æŸ¥æ¢¯åº¦
    for name, param in model.named_parameters():
        if param.requires_grad:
            print(f"   {name}: shape={param.shape}, grad={param.grad is not None}")

    # 2. æ£€æŸ¥è¾“å…¥æ•°æ®
    print("\n2. è¾“å…¥æ•°æ®æ£€æŸ¥:")
    for i, (inputs, labels) in enumerate(dataloader):
        if i >= 1:  # åªæ£€æŸ¥ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
            break

        (cd, cp, cs, pd, pp, ps) = inputs

        print(f"   æ‰¹æ¬¡ {i}:")
        print(f"     cdå½¢çŠ¶: {cd.shape}, èŒƒå›´: [{cd.min():.3f}, {cd.max():.3f}]")
        print(f"     cdå”¯ä¸€å€¼: {torch.unique(cd)}")
        print(f"     æ ‡ç­¾åˆ†å¸ƒ: æ­£={torch.sum(labels).item()}, è´Ÿ={len(labels) - torch.sum(labels).item()}")

        # æ£€æŸ¥æ˜¯å¦æœ‰NaNæˆ–Inf
        for name, tensor in [("cd", cd), ("cp", cp), ("cs", cs),
                             ("pd", pd), ("pp", pp), ("ps", ps)]:
            if torch.isnan(tensor).any():
                print(f"    âš ï¸ {name} åŒ…å«NaN!")
            if torch.isinf(tensor).any():
                print(f"    âš ï¸ {name} åŒ…å«æ— ç©·å€¼!")

    # 3. æ£€æŸ¥ç¼–ç å™¨
    print("\n3. ç¼–ç å™¨æ£€æŸ¥:")
    print(f"   ç–¾ç—…ç¼–ç å™¨ç±»åˆ«æ•°: {len(encoders['disease'].classes_)}")
    print(f"   è¡¨å‹ç¼–ç å™¨ç±»åˆ«æ•°: {len(encoders['phenotype'].classes_)}")
    print(f"   äºšç»†èƒå®šä½ç¼–ç å™¨ç±»åˆ«æ•°: {len(encoders['subcellular'].classes_)}")

    # 4. å‰å‘ä¼ æ’­æµ‹è¯•
    print("\n4. å‰å‘ä¼ æ’­æµ‹è¯•:")
    model.eval()
    with torch.no_grad():
        for i, (inputs, _) in enumerate(dataloader):
            if i >= 2:
                break

            (cd, cp, cs, pd, pp, ps) = inputs
            cd, cp, cs, pd, pp, ps = cd.to(device), cp.to(device), cs.to(device), pd.to(device), pp.to(device), ps.to(
                device)

            # é€å±‚æ£€æŸ¥
            logits = model(cd, cp, cs, pd, pp, ps)
            probs = torch.sigmoid(logits)

            print(f"   æ‰¹æ¬¡ {i}:")
            print(f"     è¾“å…¥å½¢çŠ¶: cd={cd.shape}")
            print(f"     è¾“å‡ºlogits: {logits}")
            print(f"     é¢„æµ‹æ¦‚ç‡: {probs}")

            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦ç›¸åŒ
            if i == 0:
                first_logits = logits
            else:
                if torch.allclose(first_logits, logits, rtol=1e-3):
                    print("    âš ï¸ ä¸åŒæ‰¹æ¬¡çš„è¾“å‡ºå®Œå…¨ç›¸åŒï¼")

    # 5. æ£€æŸ¥æ¨¡å‹æƒé‡
    print("\n5. æ¨¡å‹æƒé‡æ£€æŸ¥:")
    layer_stats = []
    for name, param in model.named_parameters():
        if param.requires_grad:
            stats = {
                'name': name,
                'mean': param.mean().item(),
                'std': param.std().item(),
                'min': param.min().item(),
                'max': param.max().item(),
                'zero_ratio': (param == 0).sum().item() / param.numel()
            }
            layer_stats.append(stats)

            if stats['std'] < 1e-6:
                print(f"    âš ï¸ {name}: æƒé‡æ ‡å‡†å·®å¤ªå° ({stats['std']:.6f})")
            if stats['zero_ratio'] > 0.9:
                print(f"    âš ï¸ {name}: è¶…è¿‡90%çš„æƒé‡ä¸º0")

    return layer_stats


# ä½¿ç”¨è¯Šæ–­å‡½æ•°


if __name__ == '__main__':
    DeepETD_predict(config_path='config.yaml')

